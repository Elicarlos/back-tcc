from fastapi import FastAPI, HTTPException
from schemas import TextRequest
import uvicorn
import httpx
import os
import json
import asyncio
from typing import Optional, Dict, List
from fastapi.middleware.cors import CORSMiddleware
import google.generativeai as genai


LANGUAGETOOL_URL = os.getenv("LANGUAGETOOL_URL", "http://127.0.0.1:8010")
LANGUAGETOOL_TIMEOUT = float(os.getenv("LANGUAGETOOL_TIMEOUT", "30.0"))


GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyA8wznDIh3Vhi3dgovlCE47Azb1_q6-FCQ")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-pro")
ENABLE_LLM = os.getenv("ENABLE_LLM", "true").lower() == "true"

# Configura o Gemini se a chave estiver dispon√≠vel
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)


app = FastAPI(
    title="Api para o TCC",
    description="API desenvolvida para o Trabalho de Conclus√£o de Curso (TCC) do curso de Licenciatura em Computa√ß√£o IFPI- Zona Sul.",
    version="1.0.0",
    contact={
        "name": "Elicarlos Ferreira",
        "url": "https://seu-portfolio.com",
        "email": "elicarlosantos_@hotmail.com"
    }
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",  # Porta padr√£o do Vite
        "http://localhost:3000",  # Porta alternativa do React
        "http://127.0.0.1:5173",   # Alternativa com 127.0.0.1
        "http://127.0.0.1:3000",
        
    ],
    allow_credentials=True,
    allow_methods=["*"],  # Permite todos os m√©todos (GET, POST, etc.)
    allow_headers=["*"],  # Permite todos os headers
)



http_client: Optional[httpx.AsyncClient] = None

# Cache para o modelo v√°lido encontrado
_modelo_gemini_cache = None


def listar_modelos_disponiveis():
    """Lista todos os modelos dispon√≠veis na API"""
    try:
        models = genai.list_models()
        modelos_validos = []
        print("Modelos dispon√≠veis na API:")
        for model in models:
            if 'generateContent' in model.supported_generation_methods:
                print(f"  - {model.name} (suporta generateContent)")
                modelos_validos.append(model.name)
        return modelos_validos
    except Exception as e:
        print(f"Erro ao listar modelos: {e}")
        return []


def obter_modelo_gemini():
    """Obt√©m um modelo Gemini v√°lido, tentando v√°rios nomes e testando com uma chamada real"""
    global _modelo_gemini_cache
    
    # Se j√° encontrou um modelo v√°lido antes, reutiliza
    if _modelo_gemini_cache is not None:
        return _modelo_gemini_cache
    
    # Primeiro, tenta listar modelos dispon√≠veis
    modelos_disponiveis = listar_modelos_disponiveis()
    
    # Prepara lista de modelos para tentar
    modelos_tentativas = []
    
    # Se encontrou modelos dispon√≠veis, usa eles primeiro
    if modelos_disponiveis:
        # Remove prefixo "models/" se existir e adiciona ambas as vers√µes
        for modelo in modelos_disponiveis[:5]:  # Limita a 5 para n√£o demorar muito
            modelos_tentativas.append(modelo)
            # Tenta tamb√©m sem o prefixo "models/"
            if modelo.startswith("models/"):
                modelos_tentativas.append(modelo.replace("models/", ""))
    
    # Adiciona modelos padr√£o como fallback
    modelos_tentativas.extend([
        "gemini-1.5-flash",
        "gemini-1.5-pro", 
        "gemini-pro"
    ])
    
    # Remove duplicatas mantendo ordem
    modelos_tentativas = list(dict.fromkeys(modelos_tentativas))
    
    print(f"Tentando {len(modelos_tentativas)} modelos...")
    
    for modelo_nome in modelos_tentativas:
        try:
            model = genai.GenerativeModel(model_name=modelo_nome)
            # Testa se o modelo realmente funciona fazendo uma chamada simples
            try:
                test_response = model.generate_content(
                    "Teste",
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=10
                    )
                )
                if test_response and test_response.text:
                    print(f"‚úì Modelo Gemini dispon√≠vel e funcional: {modelo_nome}")
                    _modelo_gemini_cache = model  # Cacheia o modelo v√°lido
                    return model
            except Exception as test_error:
                error_msg = str(test_error)
                # N√£o imprime todos os erros 404 para evitar spam
                if "404" not in error_msg:
                    print(f"‚úó Modelo {modelo_nome} criado mas n√£o funcional: {error_msg[:80]}")
                continue
        except Exception as e:
            error_msg = str(e)
            if "404" not in error_msg:
                print(f"‚úó Modelo {modelo_nome} n√£o dispon√≠vel: {error_msg[:80]}")
            continue
    
    print("‚ö† Erro: Nenhum modelo Gemini dispon√≠vel ap√≥s testar todas as op√ß√µes")
    return None


async def get_pontuacao_sugestao(text: str):
    """ Usa Google Gemini para sugerir pontua√ß√£o """
    if not ENABLE_LLM:
        print("LLM desabilitado (ENABLE_LLM=false)")
        return None
    
    if not GEMINI_API_KEY:
        print("GEMINI_API_KEY n√£o configurada")
        return None
    
    print(f"Chamando a API do Google Gemini (modelo: {GEMINI_MODEL})")
    
    prompt = f"""Voc√™ √© um especialista em pontua√ß√£o em portugu√™s.
    Analise o texto e sugira onde adicionar v√≠rgulas e pontos para melhorar a clareza.
Responda APENAS com o texto corrigido, sem explica√ß√µes ou coment√°rios adicionais.

    Texto: {text}
    Corre√ß√£o:"""

    try: 
        model = obter_modelo_gemini()
        if model is None:
            return None
        
        # Configura√ß√µes de gera√ß√£o
        generation_config = genai.types.GenerationConfig(
            temperature=0.3,
            max_output_tokens=500,
        )
        
        print("Enviando requisi√ß√£o para o Gemini...")
        response = model.generate_content(
            prompt,
            generation_config=generation_config
        )
        
        if response and response.text:
            return response.text.strip()
        
        return None
            
    except Exception as e:
        print(f"Erro ao chamar Gemini: {str(e)}")
        return None


async def enriquecer_match_com_ia(texto: str, match: Dict) -> Dict:
    """Enriquece cada erro encontrado pelo LanguageTool com explica√ß√µes did√°ticas da IA"""
    if not ENABLE_LLM or not GEMINI_API_KEY:
        return match
    
    try:
        erro_texto = texto[match["offset"]:match["offset"] + match["length"]]
        contexto_antes = texto[max(0, match["offset"]-30):match["offset"]]
        contexto_depois = texto[match["offset"] + match["length"]:match["offset"] + match["length"] + 30]
        
        sugestoes = match.get("replacements", [])
        sugestoes_texto = ", ".join([s.get("value", s) if isinstance(s, dict) else str(s) for s in sugestoes[:3]])
        
        prompt = f"""Voc√™ √© um professor de portugu√™s especializado em reda√ß√£o.

Erro encontrado: "{erro_texto}"
Contexto: "{contexto_antes}[ERRO]{contexto_depois}"
Mensagem do LanguageTool: {match["message"]}
Sugest√µes de corre√ß√£o: {sugestoes_texto}

Forne√ßa uma explica√ß√£o did√°tica e curta (m√°ximo 2 linhas) sobre este erro, explicando por que est√° errado e como corrigir.
Responda APENAS com a explica√ß√£o, sem formata√ß√£o ou prefixos."""

        # Tenta usar modelos alternativos se o padr√£o falhar
        model = obter_modelo_gemini()
        if model is None:
            return match
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=150
            )
        )
        
        if response and response.text:
            match["ai_explanation"] = response.text.strip()
            
    except Exception as e:
        print(f"Erro ao enriquecer match com IA: {e}")
    
    return match


async def melhorar_sugestoes_com_ia(texto: str, match: Dict) -> Dict:
    """Usa IA para melhorar ou gerar sugest√µes quando LanguageTool tem poucas op√ß√µes"""
    if not ENABLE_LLM or not GEMINI_API_KEY:
        return match
    
    # Se j√° tem 3 ou mais sugest√µes boas, n√£o precisa melhorar
    sugestoes_existentes = match.get("replacements", [])
    if len(sugestoes_existentes) >= 3:
        return match
    
    try:
        erro_texto = texto[match["offset"]:match["offset"] + match["length"]]
        contexto_antes = texto[max(0, match["offset"]-30):match["offset"]]
        contexto_depois = texto[match["offset"] + match["length"]:match["offset"] + match["length"] + 30]
        
        prompt = f"""O texto cont√©m um erro neste trecho:
"{erro_texto}" no contexto: "{contexto_antes}[ERRO]{contexto_depois}"

Erro detectado: {match["message"]}

Sugira 3 alternativas de corre√ß√£o adequadas ao contexto de uma reda√ß√£o formal.
Responda APENAS com uma lista JSON no formato: ["sugest√£o1", "sugest√£o2", "sugest√£o3"]"""

        # Tenta usar modelos alternativos se o padr√£o falhar
        model = obter_modelo_gemini()
        if model is None:
            return match
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.4,
                max_output_tokens=200
            )
        )
        
        if response and response.text:
            # Tenta extrair JSON da resposta
            resposta_texto = response.text.strip()
            # Remove markdown code blocks se houver
            if "```json" in resposta_texto:
                resposta_texto = resposta_texto.split("```json")[1].split("```")[0].strip()
            elif "```" in resposta_texto:
                resposta_texto = resposta_texto.split("```")[1].split("```")[0].strip()
            
            try:
                sugestoes_ia = json.loads(resposta_texto)
                if isinstance(sugestoes_ia, list):
                    # Combina com sugest√µes existentes
                    sugestoes_existentes_valores = [
                        s.get("value", s) if isinstance(s, dict) else str(s) 
                        for s in sugestoes_existentes
                    ]
                    todas_sugestoes = list(set(sugestoes_existentes_valores + sugestoes_ia))
                    # Converte de volta para o formato esperado
                    match["replacements"] = [{"value": s} for s in todas_sugestoes[:5]]
            except json.JSONDecodeError:
                print(f"Erro ao parsear JSON das sugest√µes: {resposta_texto}")
            
    except Exception as e:
        print(f"Erro ao melhorar sugest√µes com IA: {e}")
    
    return match


async def detectar_erros_acentuacao_com_ia(texto: str, matches_languagetool: List[Dict]) -> List[Dict]:
    """Usa IA para detectar erros de acentua√ß√£o que o LanguageTool pode ter perdido"""
    if not ENABLE_LLM or not GEMINI_API_KEY:
        return []
    
    # Se j√° tem muitos erros detectados, n√£o precisa verificar com IA
    if len(matches_languagetool) > 5:
        return []
    
    try:
        prompt = f"""Voc√™ √© um especialista em gram√°tica portuguesa do Brasil.

Analise este texto e identifique TODOS os erros de acentua√ß√£o.
Texto: "{texto}"

Responda APENAS com um JSON array v√°lido (sem texto adicional, sem markdown, sem explica√ß√µes):
[
  {{
    "palavra": "palavra sem acento",
    "correcao": "palavra corrigida",
    "mensagem": "explica√ß√£o curta"
  }}
]

Se n√£o houver erros, retorne: []"""

        model = obter_modelo_gemini()
        if model is None:
            return []
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,
                max_output_tokens=400,
                response_mime_type="application/json"  # For√ßa resposta em JSON
            )
        )
        
        if response and response.text:
            resposta_texto = response.text.strip()
            
            # Remove markdown code blocks se houver
            if "```json" in resposta_texto:
                resposta_texto = resposta_texto.split("```json")[1].split("```")[0].strip()
            elif "```" in resposta_texto:
                resposta_texto = resposta_texto.split("```")[1].split("```")[0].strip()
            
            # Tenta extrair JSON array mesmo se houver texto adicional
            import re
            json_match = re.search(r'\[[^\]]*(?:\{[^\}]*\}[^\]]*)*\]', resposta_texto, re.DOTALL)
            if json_match:
                resposta_texto = json_match.group(0)
            
            try:
                erros_ia = json.loads(resposta_texto)
                if isinstance(erros_ia, list) and len(erros_ia) > 0:
                    # Converte para o formato esperado
                    erros_formatados = []
                    for erro in erros_ia:
                        # Encontra a posi√ß√£o exata no texto (case insensitive)
                        palavra_erro = erro.get("palavra", "").strip()
                        correcao = erro.get("correcao", "").strip()
                        
                        if not palavra_erro or not correcao:
                            continue
                        
                        # Busca case-insensitive
                        offset = texto.lower().find(palavra_erro.lower())
                        
                        if offset != -1:
                            # Verifica se j√° n√£o foi detectado pelo LanguageTool
                            ja_detectado = any(
                                m.get("offset") == offset and m.get("length") == len(palavra_erro)
                                for m in matches_languagetool
                            )
                            
                            if not ja_detectado:
                                erros_formatados.append({
                                    "message": erro.get("mensagem", f"Erro de acentua√ß√£o: '{palavra_erro}' deveria ser '{correcao}'"),
                                    "replacements": [{"value": correcao}],
                                    "offset": offset,
                                    "length": len(palavra_erro),
                                    "ruleId": "AI_ACCENT_CHECK",
                                    "context": {},
                                    "source": "IA"
                                })
                    
                    if erros_formatados:
                        print(f"‚úì IA detectou {len(erros_formatados)} erro(s) de acentua√ß√£o que o LanguageTool n√£o encontrou")
                    return erros_formatados
            except json.JSONDecodeError:
                print(f"Erro ao parsear JSON da verifica√ß√£o de acentua√ß√£o: {resposta_texto}")
        
        return []
    except Exception as e:
        print(f"Erro ao detectar erros de acentua√ß√£o com IA: {e}")
        return []


async def analisar_redacao_completa(texto: str, matches: List[Dict]) -> Optional[Dict]:
    """An√°lise geral da reda√ß√£o usando IA - usado quando n√£o h√° erros b√°sicos"""
    if not ENABLE_LLM or not GEMINI_API_KEY:
        return None
    
    try:
        num_erros = len(matches)
        
        if num_erros == 0:
            prompt = f"""Analise esta reda√ß√£o e responda SOMENTE com JSON v√°lido (sem texto adicional):

Texto: "{texto}"

Responda APENAS com este JSON (sem explica√ß√µes, sem markdown, sem texto antes ou depois):
{{
    "estrutura_ok": true/false,
    "coesao": "an√°lise sobre coes√£o",
    "coerencia": "an√°lise sobre coer√™ncia",
    "sugestoes_gerais": ["sugest√£o1", "sugest√£o2", "sugest√£o3"],
    "nivel_estimado": "b√°sico/intermedi√°rio/avan√ßado",
    "pontos_fortes": ["ponto1", "ponto2"],
    "pontos_melhoria": ["melhoria1", "melhoria2"],
    "nota_estimada": "nota 0-1000"
}}"""
        else:
            # An√°lise b√°sica quando ainda h√° alguns erros
            erros_resumo = "\n".join([f"- {m['message']}" for m in matches[:3]])
            prompt = f"""Analise esta reda√ß√£o e responda SOMENTE com JSON v√°lido:

Texto: "{texto}"
Erros encontrados: {num_erros}

Responda APENAS com este JSON (sem explica√ß√µes, sem markdown):
{{
    "coesao": "an√°lise breve",
    "coerencia": "an√°lise breve",
    "sugestoes_gerais": ["sugest√£o1", "sugest√£o2"],
    "nivel_estimado": "b√°sico/intermedi√°rio/avan√ßado",
    "mensagem": "Corrija os erros b√°sicos para obter an√°lise completa"
}}"""

        # Tenta usar modelos alternativos se o padr√£o falhar
        model = obter_modelo_gemini()
        if model is None:
            return None
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=800,
                response_mime_type="application/json"  # For√ßa resposta em JSON
            )
        )
        
        if response and response.text:
            resposta_texto = response.text.strip()
            
            # Remove markdown code blocks se houver
            if "```json" in resposta_texto:
                resposta_texto = resposta_texto.split("```json")[1].split("```")[0].strip()
            elif "```" in resposta_texto:
                resposta_texto = resposta_texto.split("```")[1].split("```")[0].strip()
            
            # Tenta extrair JSON mesmo se houver texto adicional antes/depois
            import re
            # Procura por um objeto JSON completo (com chaves balanceadas)
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', resposta_texto, re.DOTALL)
            if json_match:
                resposta_texto = json_match.group(0)
            else:
                # Se n√£o encontrou objeto, tenta array
                json_match = re.search(r'\[[^\[]*(?:\{[^\}]*\}[^\[]*)*\]', resposta_texto, re.DOTALL)
                if json_match:
                    resposta_texto = json_match.group(0)
            
            try:
                resultado = json.loads(resposta_texto)
                # Verifica se √© um dict v√°lido
                if isinstance(resultado, dict):
                    return resultado
                else:
                    print(f"Resposta n√£o √© um objeto JSON v√°lido: {type(resultado)}")
                    return None
            except json.JSONDecodeError as e:
                # Se falhar, tenta extrair informa√ß√µes manualmente
                print(f"Erro ao parsear JSON da an√°lise completa: {str(e)}")
                print(f"Resposta recebida: {resposta_texto[:300]}")
                return {
                    "an√°lise_texto": resposta_texto[:500],
                    "erro_parse": True,
                    "mensagem": "Erro ao processar resposta da IA. A IA retornou texto em vez de JSON."
                }
        
        return None
            
    except Exception as e:
        print(f"Erro na an√°lise completa: {e}")
        return None

@app.get("/")
async def read_root():
    """ Rota raiz para verificar se a API est√° funcionando. """
    return {
        "status": "API de verifica√ß√£o de texto online. Use o endpoint POST /v2/check",
        "languagetool_url": LANGUAGETOOL_URL,
        "health": "ok"
    }

@app.get("/health")
async def health_check():
    """ Endpoint de health check para monitoramento. """
    health_status = {
        "status": "healthy",
        "services": {}
    }
    
    # Verificar LanguageTool
    try:
        if http_client is None:
            health_status["services"]["languagetool"] = {"status": "unavailable", "reason": "HTTP client not initialized"}
        else:
            response = await http_client.get(
                f"{LANGUAGETOOL_URL}/v2/languages",
                timeout=5.0
            )
            if response.status_code == 200:
                health_status["services"]["languagetool"] = {"status": "connected", "url": LANGUAGETOOL_URL}
            else:
                health_status["services"]["languagetool"] = {"status": "degraded", "status_code": response.status_code}
    except Exception as e:
        health_status["services"]["languagetool"] = {"status": "unavailable", "error": str(e)}
        health_status["status"] = "degraded"
    
    # Verificar Google Gemini (LLM)
    try:
        if not ENABLE_LLM:
            health_status["services"]["gemini"] = {"status": "disabled", "reason": "ENABLE_LLM=false"}
        elif not GEMINI_API_KEY:
            health_status["services"]["gemini"] = {
                "status": "unavailable",
                "error": "GEMINI_API_KEY n√£o configurada",
                "suggestion": "Configure a vari√°vel de ambiente GEMINI_API_KEY"
            }
            health_status["status"] = "degraded"
        else:
            # Testa se consegue listar os modelos (indica que a API est√° funcionando)
            try:
                models = genai.list_models()
                health_status["services"]["gemini"] = {
                        "status": "connected",
                    "model_configured": GEMINI_MODEL,
                    "api_available": True
                }
            except Exception as e:
                health_status["services"]["gemini"] = {
                    "status": "degraded",
                    "error": str(e),
                    "model_configured": GEMINI_MODEL
        }
        health_status["status"] = "degraded"
    except Exception as e:
        health_status["services"]["gemini"] = {"status": "unavailable", "error": str(e)}
        health_status["status"] = "degraded"
    
    return health_status

@app.on_event("startup")
async def startup_event():
    """ 
    Esta fun√ß√£o √© executada quando a aplica√ß√£o inicia.
    Cria cliente HTTP reutiliz√°vel e verifica conectividade com LanguageTool.
    """
    global http_client
    
    print(f"Conectando ao servidor LanguageTool ({LANGUAGETOOL_URL})...")

    try:
        # Cria cliente HTTP reutiliz√°vel (melhor performance)
        http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(LANGUAGETOOL_TIMEOUT),
            limits=httpx.Limits(max_keepalive_connections=10, max_connections=20)
        )
        
        # Testa conectividade
        response = await http_client.get(f"{LANGUAGETOOL_URL}/v2/languages", timeout=5.0)
        
        if response.status_code == 200:
            print("‚úì Conectado ao LanguageTool com sucesso.")
        else:
            print(f"‚ö† LanguageTool respondeu com status {response.status_code}")
            
    except httpx.ConnectError:
        print(f"‚úó ERRO: N√£o foi poss√≠vel conectar ao LanguageTool em {LANGUAGETOOL_URL}")
        print(f"Verifique se o cont√™iner Docker 'erikvl87/languagetool' est√° rodando.")
        http_client = None
    except Exception as e:
        print(f"‚úó ERRO: Falha ao inicializar cliente HTTP: {e}")
        http_client = None

@app.on_event("shutdown")
async def shutdown():
    """ Esta fun√ß√£o √© executada para desligar o servidor. """
    global http_client
    
    print("Servidor FastAPI desligando...")
    try:
        if http_client is not None:
            await http_client.aclose()
            http_client = None
    except Exception as e:
        print(f"Aviso durante shutdown: {e}")

@app.post("/v2/check")
async def check_text(request_data: TextRequest):
    """ Recebe o texto e verifica erros gramaticais usando LanguageTool (sem IA autom√°tica). """
    
    if http_client is None:
        raise HTTPException(
            status_code=503,
            detail="LanguageTool n√£o est√° dispon√≠vel. Verifique os logs do servidor."
        )

    if not request_data.text or not request_data.text.strip():
        raise HTTPException(
            status_code=400,
            detail="Texto n√£o pode estar vazio."
        )

    try:
        # 1. Busca erros com LanguageTool
        response = await http_client.post(
            f"{LANGUAGETOOL_URL}/v2/check",
            data={
                "text": request_data.text,
                "language": "pt-BR",
                "level": "picky",
                "enabledOnly": "false",  # Habilita todas as regras dispon√≠veis
            }
        )
        
        response.raise_for_status()
        data = response.json()
        
        # 2. Formata matches b√°sicos
        formatted_matches = []
        for match in data.get("matches", []):
            formatted_match = {
                "message": match.get("message", ""),
                "replacements": match.get("replacements", []),
                "offset": match.get("offset", 0),
                "length": match.get("length", 0),
                "ruleId": match.get("rule", {}).get("id", ""),
                "context": match.get("context", {}),
            }
            formatted_matches.append(formatted_match)
        
        # 3. Se n√£o encontrou erros com LanguageTool e IA est√° habilitada, tenta detectar erros de acentua√ß√£o com IA
        # Isso complementa o LanguageTool detectando erros que ele pode ter perdido
        if ENABLE_LLM and GEMINI_API_KEY:
            erros_acentuacao = await detectar_erros_acentuacao_com_ia(request_data.text, formatted_matches)
            formatted_matches.extend(erros_acentuacao)
        
        num_erros = len(formatted_matches)
        
        # IA n√£o √© mais chamada automaticamente - apenas quando o usu√°rio solicitar via bot√£o
        # Isso economiza quota e d√° controle ao usu√°rio

        return {
            "original_text": request_data.text,
            "corrections_found": num_erros,
            "matches": formatted_matches,
            "ai_enabled": ENABLE_LLM and bool(GEMINI_API_KEY),
            "ai_ready": num_erros == 0,  # Indica se o texto est√° pronto para an√°lise completa com IA
            "suggestion": "Corrija os erros b√°sicos e clique em 'An√°lise Completa com IA' para obter an√°lise detalhada" if num_erros > 0 else None
        }
        
    except httpx.TimeoutException:
        raise HTTPException(
            status_code=504,
            detail="Timeout ao conectar ao LanguageTool. Tente novamente."
        )
    except httpx.ConnectError:
        raise HTTPException(
            status_code=503,
            detail="N√£o foi poss√≠vel conectar ao LanguageTool. Servi√ßo pode estar offline."
        )
    except httpx.HTTPStatusError as e:
        raise HTTPException(
            status_code=e.response.status_code,
            detail=f"Erro do servidor LanguageTool: {e.response.text}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno: {str(e)}"
        )


@app.post("/v2/analyze")
async def analyze_with_ai(request_data: TextRequest):
    """Endpoint separado para an√°lise completa com IA - acionado manualmente pelo usu√°rio"""
    if not ENABLE_LLM or not GEMINI_API_KEY:
        raise HTTPException(
            status_code=503,
            detail="IA n√£o est√° habilitada. Configure GEMINI_API_KEY."
        )
    
    if not request_data.text or not request_data.text.strip():
        raise HTTPException(
            status_code=400,
            detail="Texto n√£o pode estar vazio."
        )
    
    try:
        # Primeiro verifica erros b√°sicos com LanguageTool
        if http_client is None:
            raise HTTPException(
                status_code=503,
                detail="LanguageTool n√£o est√° dispon√≠vel."
            )
        
        response = await http_client.post(
            f"{LANGUAGETOOL_URL}/v2/check",
            data={
                "text": request_data.text,
                "language": "pt-BR",
                "level": "picky",
                "enabledOnly": "false",
            }
        )
        
        response.raise_for_status()
        data = response.json()
        
        formatted_matches = []
        for match in data.get("matches", []):
            formatted_match = {
                "message": match.get("message", ""),
                "replacements": match.get("replacements", []),
                "offset": match.get("offset", 0),
                "length": match.get("length", 0),
                "ruleId": match.get("rule", {}).get("id", ""),
                "context": match.get("context", {}),
            }
            formatted_matches.append(formatted_match)
        
        # Tamb√©m verifica erros de acentua√ß√£o com IA se dispon√≠vel
        if ENABLE_LLM and GEMINI_API_KEY:
            erros_acentuacao = await detectar_erros_acentuacao_com_ia(request_data.text, formatted_matches)
            formatted_matches.extend(erros_acentuacao)
        
        num_erros = len(formatted_matches)
        
        # An√°lise completa com IA
        print("ü§ñ Iniciando an√°lise completa com IA...")
        ai_analysis = await analisar_redacao_completa(request_data.text, formatted_matches)
        llm_punctuation_suggestion = None
        
        # Sugest√£o de pontua√ß√£o apenas se n√£o houver erros
        if num_erros == 0:
            llm_punctuation_suggestion = await get_pontuacao_sugestao(request_data.text)
        
        return {
            "original_text": request_data.text,
            "corrections_found": num_erros,
            "matches": formatted_matches,
            "llm_punctuation_suggestion": llm_punctuation_suggestion,
            "ai_analysis": ai_analysis,
            "ai_used": bool(ai_analysis or llm_punctuation_suggestion),
            "ai_ready": num_erros == 0
        }
        
    except httpx.TimeoutException:
        raise HTTPException(status_code=504, detail="Timeout ao conectar ao LanguageTool.")
    except httpx.ConnectError:
        raise HTTPException(status_code=503, detail="LanguageTool offline.")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

if __name__ == "__main__":
    print("Iniciando o servidor FastAPI... em http://127.0.0.1:8000")
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)